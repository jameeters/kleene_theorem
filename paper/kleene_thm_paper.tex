\documentclass{bcthesis}

%%% Other packages needed by your document may be loaded here.
\usepackage{url}              % For formatting URLs 
\usepackage{booktabs}         % Publication-quality tables.
\usepackage[square, numbers]{natbib}           % Provides some nice citation and
							  % bibliography formatting commands.
% \bibpunct[:~]{(}{)}{;}{a}{,}{,~} % Set some defaults for bibliographic
								 % punctuation used by natbib.sty.
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{subfig} % Because subcaption does not seem to be compatible with the template.
\usepackage{calc}
\usepackage{textcomp}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{bm}
\usepackage{tikz}
\usepackage{float}
% \usepackage{showframe}
\usepackage{james}
\usepackage[plainpages=false,pdfpagelabels, hidelinks]{hyperref}

\usetikzlibrary{arrows, automata, shapes}

%%% Document Settings
	% The following command allows tables to split between pages:
	% \allowdisplaybreaks

	% Provide additional context around errors. 
	\setcounter{errorcontextlines}{1000}

	\setlength{\parskip}{0.5 em}

	\newif\ifbuildfrontmatter
	\buildfrontmatterfalse
	% \buildfrontmattertrue

	\allhrfalse

	% Use this to toggle professionalism
	\newif\ifpresstime
	\presstimefalse
	\presstimetrue

	\ifpresstime
		\buildfrontmattertrue
		\renewcommand{\meo}[1]{}
		\allhrfalse
	\fi

	\tikzset{
		initial text = {\scriptsize{\textsc{start}}},
		initial distance = 1 pt,
		every initial by arrow/.style={->},
		elliptic state/.style={draw,rounded rectangle}
	}


%%% End document settings

%%% Begin information section 
	%% title of your report?
	\title{An Exemplified Proof of Kleene's Theorem}

	%% Your name 
	\author{James McFeeters}

	% Photo -- see bcthesis class line 168

	\advisor{Darrah Chavey}

	%% Second reader's name? Ask the Colloquium Instructor who it will be.
	\reader{Placeholder Name}

	\thesisyear{2018}
	\thesismonth{March}
%%% End of information section.


%%% New Environments

%%% End new environments 

%%% New commands
	% \pcite makes more sense, but the syntax highlighting is better on \footcite in my editor. No idea.
	\newcommand{\footcite}[2]{\xspace\cite[pg.~{#2}]{#1}\xspace}
	\newcommand{\pcite}[2]{\xspace\cite[pg.~{#2}]{#1}\xspace}
%%% End new commands


%%% The start of the document!
\begin{document}

\ifbuildfrontmatter
\frontmatter

	\maketitle

	\begin{abstract}
		This paper offers a proof of Kleene's theorem, accompanied by the necessary background in formal language theory, as well as detailed examples illustrating key points. 
		There is also a brief discussion of the importance and application of Kleene's theorem in practice.		
	\end{abstract}


	%%% If you want to thank someone for their influence on your life or your work, here's where you'd do it.
	\begin{acknowledgments}
		I thank Darrah Chavey for his capable advising and for introducing me to the topic.
		I thank Cameron Kuchta for proofreading my paper, and Simon Tomlinson for proofreading my paper and assisting me in writing the program used to produce examples.
	\end{acknowledgments}

	%%% Table of Contents, List of Figures, and List of Tables. 
	% If you don't have any figures or tables in your report, you can
	% comment out the appropriate command.
	\tableofcontents
	% \listoffigures
	% \listoftables
%%% End of the front matter.
\fi

%%% Beginnning of the main matter.
\mainmatter
\mychapter{Introduction}
\label{ch:basics}

	Formal language theory is a branch of mathematics that studies the structural properties of languages, whether natural or artificial.
	In computer science, formal language theory provides a framework for the design and processing of programming languages, as well as for the classification of problems by complexity.

	Kleene's theorem establishes the equivalence of computational models known as finite automata and a family of languages called the regular languages.

	Before beginning our discussion of Kleene's theorem, we will give an introduction to the basic concepts of formal language theory necessary to an understanding of Kleene's theorem.

	\section{Basic Definitions} % (fold)
	\label{sec:basic_definitions}
		\begin{definition}[Symbol]
			The \textit{symbol} is the most basic unit of formal language theory.
			Symbols are indivisible and atomic --- they are not a composite of other units, and cannot be represented by any combination of other symbols \footcite{hopcroft}{1}.
		\end{definition}

		\begin{definition}[Alphabet]
			An \textit{alphabet} is a nonempty and finite set of symbols.
			An alphabet is typically denoted by the symbol $\Sigma$ \footcite{salomaa}{1}.
		\end{definition}

		\begin{definition}[String]
			A \textit{string} or \textit{word} over an alphabet $\Sigma$ is a finite sequence of symbols of $\Sigma$.
			If $\Sigma = \{ a, b ,c \}$, then $w = abbc$ is a string over $\Sigma$.
			The \textit{length} of a string is the number of symbols it contains, counting repetitions.
			The length of $w$, denoted $|w|$, is $4$ \footcite{hopcroft}{1}.

			The string of length zero, which contains no symbols, is called the \textit{empty string}, and denoted $\lambda$.
			The empty string is a valid string over any alphabet \footcite{salomaa}{1}.
		\end{definition}

		\begin{definition}[Language]
			A \textit{language} over an alphabet $\Sigma$ is any set of strings over $\Sigma$ \footcite{hopcroft}{2}.

			Because languages are sets of strings, the conventional set operations, such as union, intersection, and complementation are defined for languages \footcite{hopcroft}{5}.

			The empty set , written $\emptyset$, and $\{ \lambda \}$ are valid languages over any alphabet \footcite{hopcroft}{2}.
		\end{definition}

		\begin{remark}
			The empty set and $\{ \lambda \}$ represent distinct languages. 
			The empty set represents the language containing no strings at all, while $\{ \lambda \}$ represents the language containing only the empty string \footcite{hopcroft}{2}.
		\end{remark}
	% section basic_definitions (end)
% chapter intoduction (end)

\mychapter{Regular Languages and Regular Expressions} % (fold)
\label{ch:regular_languages_and_expressions}
	
	This section introduces the family of regular languages, as defined from a set-theoretic perspective.
	We also introduce the widely-used system of notation known as regular expressions.

	\section{Regular Languages} % (fold)
	\label{sec:regular_languages}

		\begin{definition}[Atomic Regular Languages]
			The \textit{atomic regular languages} are the basic units used to build regular languages.
			They are defined for any alphabet $\Sigma$ as follows:

			\begin{enumerate}[label=(\roman*), itemsep = -0.3 ex, nolistsep]
				\item $\emptyset$ is an atomic regular language over $\Sigma$.
				\item $\{ \lambda \}$ is an atomic regular language over $\Sigma$.
				\item $\{ a \}$ is an atomic regular language over $\Sigma$ for any $a \in \Sigma$.
			\end{enumerate}
			\footcite{hopcroft}{28}~ \meo{todo: something about this citation.}
		\end{definition}

		We now define the operations used to combine the atomic regular languages to form more complex regular languages.

		\begin{definition}[Concatenation]
			Let $w_1 = ab$ and $w_2 = bc$ be strings over some alphabet.
			Their \textit{concatenation}, written $w_1 w_2$ denotes the string $abbc$, and $w_2 w_1$ denotes $bcab$.
			For any string $w$, $\lambda w = w \lambda = w$.
			The notation $w^3$ denotes the string $www$, and $w^0 = \lambda$ \footcite{salomaa}{1}.

			It should be easy to see how this definition applies to symbols, which can be seen as words of length one.
		\end{definition}

		\begin{definition}[Concatenation of Languages]
			If $A$ and $B$ are languages over some alphabet, then the set
			\[
				AB = \{ ab \mid a \in A, \ b \in B \}
			\]
			is called the \textit{concatenation}, or \textit{product} of $A$ and $B$ \footcite{lemmings}{3}.

			The notation $A^2$ represents the language $AA$, and $A^i$ represents $AA^{i-1}$.
			Note that $A = A^1 = AA^0 = \{ a \lambda \mid a \in A \}$, which implies that $A^0 = \{ \lambda \}$ \footcite{lemmings}{3}.
		\end{definition}

		\begin{remark}
			Note that the set of strings over an alphabet is closed under concatenation: if $x$ and $y$ are strings over $\Sigma$, then so are $xy$ and $yx$.
			It follows that if $A$ and $B$ are languages over $\Sigma$, then so are $AB$ and $BA$ \footcite{lemmings}{2}.
			
			Concatenation is also an associative operation.
			Given strings $x$, $y$, and $z$, $(xy)z = x(yz)$.
			It follows that for languages $A$, $B$, and $C$, ${(AB)C = A(BC)}$ \footcite{lemmings}{2}.

			\meo{
				Maybe also note that length has the properties of the logarithm with regard to concatenation.
				It's a curiosity, but not really useful information
			}

		\end{remark}

		\begin{definition}[Kleene Closure]
			Given any language $A$, the language 
			\[
				A^* = \bigcup_{i \geq 0} A^i
			\]
			is called the \textit{Kleene closure} of $A$.
			$A^*$ is the language containing any words of $A$ repeated zero or more times, thus $\lambda$ is in the Kleene closure of any language.
			The Kleene closure of an alphabet is the set of all words over that alphabet \footcite{lemmings}{3}.
		\end{definition}

		\begin{definition}[Regular Language]
			Given an alphabet $\Sigma$, any atomic regular language over $\Sigma$ is a regular language over $\Sigma$.
			
			If $A$ and $B$ are regular languages over $\Sigma$, then so are 
			\begin{enumerate}[label=(\roman*), itemsep = -0.3 ex, nolistsep]
				\item $AB$
				\item $A \cup B$
				\item $A^*$
			\end{enumerate}
			\footcite{rosen}{879}~\meo{todo: something about this citation}
		\end{definition}

		\begin{remark}
			Because of their relationship to the family of regular languages, the concatenation, union, and Kleene closure are referred to as the \textit{regular operations} \footcite{salomaa}{26}.
		\end{remark}
	% section regular_languages (end)

	\clearpage

	\section{Regular Expressions} % (fold)
	\label{sec:regular_expressions}

		We now introduce \textit{regular expressions}, a shorthand used to describe regular languages.

		\begin{definition}[Regular Expressions]
			The atomic regular expressions over an alphabet $\Sigma$ are defined to represent the atomic regular languages over $\Sigma$:
			\begin{enumerate}[label=(\roman*), itemsep = -0.3 ex, nolistsep]
				\item $\emptyset$ denotes the empty language;
				\item $\lambda$ denotes the language $\{ \lambda \}$;
				\item $a$ denotes the language $\{ a \}$ for any $a \in \Sigma$.
			\end{enumerate}
			\footcite{hopcroft}{28--29}~\meo{todo: something about this citation}

			If $\alpha$ and $\beta$ are regular expressions representing languages $A$ and $B$, respectively, then the following are also regular expressions:
			\begin{enumerate}[label=(\roman*), itemsep = -0.3 ex, nolistsep]
				\item $\alpha \beta$ denotes the language $AB$;
				\item $\alpha + \beta$ denotes the language $A \cup B$;
				\item $\alpha^*$ denotes the language $A^*$.
			\end{enumerate}
			\footcite{hopcroft}{28--29}~\meo{todo: something about this citation}
		\end{definition}

		\begin{remark}
			Although regular expressions may closely resemble the the notation for regular languages, they are in fact only a shorthand used to describe regular language. 
			That is, although $\alpha \beta + \gamma \beta$ and $(\alpha + \gamma) \beta$ describe the same language, we would not consider them to be the same regular expression.
			Using regular expressions allows us to describe regular languages while avoiding some of the formalisms of set notation.
			Additionally, regular expressions are a ubiquitous tool in computer science as well as in the software industry \footcite{grep}{1}.
			\meo{
				Maybe mention that a language is regular if and only if it can be described by a regular expression.
			}
		\end{remark}


		\meo{
			I could mention here that regular expressions are an example of a grammar, shockingly belonging to the class of regular grammars.
		}
	% section regular_expressions (end)
% chapter regular_languages_and_expressions (end)

\mychapter{Finite Automata} % (fold)
\label{ch:finite_automata}

	A finite automaton is a formal model of a machine which has a finite number of allowed configurations, called states, and accepts input symbols from some finite alphabet. 
	Each time a symbol is input to the automaton, it may change state. 
	The output of a finite automaton is defined by the state of the machine after reading some input \footcite{hopcroft}{13}.
	We will deal with finite automata producing binary output --- they either ``accept'' an input, or fail to do so.

	\section{Definitions} % (fold)
	\label{sec:fa_definitions}

		\begin{definition}[Finite Automaton]
			A \textit{finite automaton} (FA) $M$ is defined by the 5-tuple $(Q, \Sigma, s, \delta, F)$, where:
			\begin{itemize}
				\item [] $Q$ is a finite and nonempty set of states;
				\item [] $\Sigma$ is an alphabet of possible input symbols;
				\item [] $s \in Q$ is the state of the machine prior to any input, referred to as the \textit{initial state};
				\item [] $\delta: (Q \times \Sigma) \mapsto Q$ is called the \textit{transition function}: It maps a starting state and an input symbol to the new state of the machine;
				\item [] $F \subseteq Q$ is the set of \textit{final states} or \textit{accepting states} of the machine.
			\end{itemize}
			\footcite{hopcroft}{17}~\meo{todo: something about this citation}
		\end{definition}

		\begin{remark}
			It is convenient to extend the definition of $\delta$ to apply to strings, as well as individual symbols.
			Let $w \in \Sigma^*$, and let $a \in \Sigma$.
			By 
			\[
				\Delta(q_1, wa) = q_n
			\] 
			we mean 
			\[
				\delta( \Delta(q_1, w), a) = q_n.
			\]
			We define $\delta(q_i, \lambda) = q_i$.
			This defines $\Delta: (Q \times \Sigma^*) \mapsto Q$ \footcite{hopcroft}{17}.
		\end{remark}

		\begin{definition}(Acceptance by Finite Automaton)
			Let $M = (Q, \Sigma, s, \delta, F)$ be an FA and let $w \in \Sigma^*$.
			We say that $w$ is \textit{accepted} by $M$ if $\Delta(s, w) \in F$ \footcite{hopcroft}{18}.

			We use $L(M)$ to denote the language $\{ w \in \Sigma^* \mid \Delta(s, w) \in F \}$ containing all strings accepted by $M$ \footcite{hopcroft}{18}.

			A language $A$ is considered \textit{representable} if there exists some FA $M_A$ such that $A = L(M_A)$ \footcite{salomaa}{20}.
		\end{definition}
	% section fa_definitions (end)

	\section{Example: Finite Automata Construction} % (fold)
	\label{sec:ex:m3_construction}
	

		% I'm done typing this out. 
		\newcommand{\miii}{\ensuremath{M_3}\xspace}

		To illustrate exactly how the components of an FA function, we will give a step-by-step construction of an FA to recognize the language of binary numbers divisible by 3.

		Call this automaton \miii.
		Let $\miii = (Q, \Sigma, s, \delta, F)$.
		Clearly we need only the symbols ``0'' and ``1'' to represent a language of binary strings, so we set $\Sigma = \{ 0, 1 \}$.

		Now we define the set of states for $\miii$.
		Suppose $x$ is the string that has been input to $\miii$ so far.
		It is clear that for any $x$, exactly one of the following must be true:
		\begin{enumerate}[label = (\roman*), itemsep = -1 ex, nolistsep]
			\item $x = 0 \mod 3$;
			\item $x = 1 \mod 3$;
			\item $x = 2 \mod 3$.
		\end{enumerate}
		So we create one state to represent each of these possible conditions, and define $Q = \{ q_0, q_1, q_2 \}$.
		Since we want $\miii$ to accept numbers divisible by 3, we set $F = \{ q_0 \}$. 
		And since we interpret the lack of input as 0, set the initial state $s$ to $q_0$.

		Now we have 
		\[
			\miii = (Q = \{ q_0, q_1, q_2 \},\ \Sigma = \{ 0, 1 \},\ s = q_0,\ \delta,\ F = \{ q_0 \}).
		\]
		The only part of \miii remaining to be defined is $\delta$, the transition function.

		To define the transition function it is helpful to have a picture of the automaton we are building.
		We draw FAs as directed graphs, with vertices representing states and edges, labeled by symbols, representing transitions.
		A double circle around a vertex means that it represents an accepting state.
		Figure~\ref{fig:m3_1} shows $\miii$ as defined thus far: lacking any transitions, but otherwise complete.


		\begin{figure}[H]
			\centering
			\begin{tikzpicture}[>=stealth',shorten >=1pt,auto,node distance=2cm]
				\node[initial,state,accepting] (0)                {$q_0$};
				\node[state]                   (1) [right of = 0] {$q_1$};
				\node[state]                   (2) [right of = 1] {$q_2$};
			\end{tikzpicture}
			\caption{$\miii$ without any transitions}
			\label{fig:m3_1}
		\end{figure}

		To define transitions, we imagine starting with the FA in its initial state and entering a string one symbol at a time.
		Each time we enter a symbol we decide what the next state of the machine should be, given the input so far, and then define a transition to produce that state.

		Suppose that $\miii$ is in its initial state.
		If the first input symbol is ``0'', then the machine should not change state.
		So we define $\delta(q_0, 0) = q_0$.
		If the first symbol is ``1'', the value of the input is $1$, so the next state should be $q_1$, and we define $\delta(q_0, 1) = q_1$.
		Figure~\ref{fig:m3_2} shows the automaton with these transitions added.

		\begin{figure}[H]
			\centering
			\begin{tikzpicture}[>=stealth',shorten >=1pt,auto,node distance=2cm]
				\node[initial,state,accepting] (q0)                 {$q_0$};
				\node[state]                   (q1) [right of = q0] {$q_1$};
				\node[state]                   (q2) [right of = q1] {$q_2$};

				\path[->, very thick](q0) edge [loop above] node {0} (q0);
				\path[->, very thick](q0) edge [bend left]  node {1} (q1);
			\end{tikzpicture}
			\caption{$\miii$ with transitions from $q_0$ added.}
			\label{fig:m3_2}
		\end{figure}

		Clearly, we do not need to add any more transitions from $q_0$, so we move on to $q_1$.
		Imagine that the input so far is ``1'', so that $\miii$ will be in state $q_1$.
		If the next symbol is ``0'', we have $10_b = 2$, and the next state should be $q_2$.
		So we define $\delta(q_1, 0) = q_2$.
		But if the next symbol is ``1'', we have $11_b = 3$. 
		Then the next state should be $q_0$, so we define $\delta(q_1, 1) = q_0$.
		Figure~\ref{fig:m3_3} shows \miii with these transitions added. 


		\begin{figure}[H]
			\centering
			\begin{tikzpicture}[>=stealth',shorten >=1pt,auto,node distance=2cm]
				\node[initial,state,accepting] (q0)                 {$q_0$};
				\node[state]                   (q1) [right of = q0] {$q_1$};
				\node[state]                   (q2) [right of = q1] {$q_2$};

				\path[->]            (q0) edge [loop above] node {0} (q0);
				\path[->]            (q0) edge [bend left]  node {1} (q1);
				\path[->, very thick](q1) edge [bend left]  node {0} (q2);
				\path[->, very thick](q1) edge [bend left]  node {1} (q0);
			\end{tikzpicture}
			\caption{\miii with transitions from $q_1$ added.}
			\label{fig:m3_3}
		\end{figure}

		Now we can define the transitions from $q_2$. 
		Imagine that the input so far is ``10''.
		If the next symbol is ``0'', we have $100_b = 4 \equiv 1 \mod 3$, so we define $\delta(q_2, 0) = q_1$.
		But if the next symbol is ``1'', we have $101_b = 5 \equiv 2 \mod 3$, so we set $\delta(q_2, 1) = q_2$.

		This completes the construction of \miii.
		Figure~\ref{fig:m3_4} shows the finished automaton.

		\begin{figure}[H]
			\centering
			\begin{tikzpicture}[>=stealth',shorten >=1pt,auto,node distance=2cm]
				\node[initial,state,accepting] (q0)                {$q_0$};
				\node[state]                   (q1) [right of = q0] {$q_1$};
				\node[state]                   (q2) [right of = q1] {$q_2$};

				\path[->]            (q0) edge [loop above] node {0} (q0);
				\path[->]            (q0) edge [bend left]  node {1} (q1);
				\path[->]            (q1) edge [bend left]  node {0} (q2);
				\path[->]            (q1) edge [bend left]  node {1} (q0);
				\path[->, very thick](q2) edge [bend left]  node {0} (q1);
				\path[->, very thick](q2) edge [loop right] node {1} (q2);
			\end{tikzpicture}
			\caption{\miii with all its transitions.}
			\label{fig:m3_4}
		\end{figure}
	% section example_finite_automata_construction (end)

	\section{Deterministic and Nondeterministic Automata} % (fold)
	\label{sec:DFA_NDFA}
	
		\begin{definition}[Deterministic and Nondeterministic Finite Automata]
			Finite automata are divided into two classes: nondeterministic and deterministic finite automata \footcite{hopcroft}{19}.
			\begin{enumerate}[label=(\roman*)]
				\item A \textit{nondeterministic} finite automaton (NDFA) is an FA with \textit{zero or more} transitions from each state corresponding to each symbol in $\Sigma$.
				\item A \textit{deterministic} finite automaton (DFA) is an FA having \textit{exactly one} transition from each state corresponding to each symbol in $\Sigma$.
			\end{enumerate}
		\end{definition}

		\begin{remark}
			Because a DFA is required to have exactly one transition from each state for each possible input, only one of its states may be active at any given time.
			This is not the case for NDFAs.
			Because an NDFA may have any number of transitions from each state on a single symbol, any subset of its states may be active at any given time.
			Alternatively, an NDFA may have no transition from any state for a given input symbol, and upon reading that symbol would have no active states.
			An NDFA is considered to be in an accepting state when any of its accepting states are active.

			This complication makes our definition of the transition function awkward to apply to NDFAs.
			For an NDFA, we define the following refinement:
			\[
				\delta : (Q \times \Sigma) \mapsto 2^Q
			\]
			where $2^Q$ is the power set (set of all subsets) of $Q$.
			This defines the result of a transition to be a set of states, rather than a single state, so rather than
			\[
				\delta(q_0, a) = q_1
			\]
			we write
			\[
				q_1 \in \delta(q_0, a).
			\]
			This refinement offers a more consistent approach to transitions in NDFAs.

			It is also convenient when dealing with any automata to be able to compare transition functions.
			Suppose that $\delta$ and $\delta'$ are transitions functions defined on the same states and alphabet.
			By
			\[
				\delta \subseteq \delta'
			\]
			we mean that
			\[
				\delta(q, a) \subseteq \delta'(q, a)
			\]
			for all $q \in Q$ and $a \in \Sigma$.

			\meo{I could mention lambda transitions, but I've avoided using them so far, so I don't think I need to.}

		\end{remark}
	% section DFA_NDFA (end)
% chapter finite_automata (end)


\mychapter{Kleene's Theorem} % (fold)
\label{ch:kleenes_theorem}

	\begin{theorem}[Kleene's Theorem]
		A language is representable if and only if it is regular.
	\end{theorem}

	\begin{claim}
	\label{prop:regular_languages_representable}
		All regular languages are representable by an NDFA.
	\end{claim}
	\begin{proof}
		We first show that the atomic regular languages are representable, then show that the result of any regular operation on representable languages is representable. The constructions used are adapted from Rosen \footcite{rosen}{880--881}.

		It is simple to construct an NDFAs to accept the atomic regular languages:
		\begin{itemize}
			\item [] $\emptyset$ is accepted by an automaton with one initial state, no accepting states, and no transitions, as depicted in Figure~\ref{sfig:ndfa_emptyset}.
			\item [] $\{ \lambda \}$ is accepted by the NDFA with one state, which is both its initial state and an accepting state, as in Figure~\ref{sfig:ndfa_lambda}.
			\item [] $\{ a \}$ for all $a \in \Sigma$ is accepted by an NDFA having two states: one initial state and one accepting state, with a transition on $a$ between them, as shown in Figure~\ref{sfig:ndfa_symbol}.
		\end{itemize}


		\begin{figure}[H]
			\centering
			\setlength{\fboxrule}{0 pt}
			\subfloat[NDFA accepting $\emptyset$]{
				\label{sfig:ndfa_emptyset}
				\framebox[0.3 \textwidth]{
					\begin{tikzpicture}[>=stealth',shorten >=1pt,auto,node distance=2cm]
						\node[initial,state] (q0)                {$q_0$};
					\end{tikzpicture}
				}
			}
			\subfloat[NDFA accepting $\{ \lambda \}$]{
				\label{sfig:ndfa_lambda}
				\framebox[0.3 \textwidth]{
					\begin{tikzpicture}[>=stealth',shorten >=1pt,auto,node distance=2cm]
						\node[initial,state, accepting] (q0)                {$q_0$};
					\end{tikzpicture}
				}
			}
			\subfloat[NDFA accepting $\{ a \}$ for all $a \in \Sigma$]{
				\label{sfig:ndfa_symbol}
				\framebox[0.3 \textwidth]{
					\begin{tikzpicture}[>=stealth',shorten >=1pt,auto,node distance=2cm]
						\node[initial,state]    (q0)                 {$q_0$};
						\node[state, accepting] (q1) [right of = q0] {$q_1$};
						\path[->](q0) edge  node {$a$} (q1);
					\end{tikzpicture}
				}
			}
			\caption{NDFAs representing the atomic regular languages}
			\label{fig:ndfa_atomic_regular_languages}
			% The \framebox makes the caption wider than the picture, 
			% otherwise, subfigures (a) and (b) are too narrow and their captions look bad.
		\end{figure}

		Now we must show that if $A$ and $B$ are representable languages, then so are
		\begin{enumerate}[label=(\roman*), itemsep = -0.3 ex, nolistsep]
			\item $AB$
			\item $A \cup B$
			\item $A^*$
		\end{enumerate}
		Starting with automata representing $A$ and $B$, we will construct automata to accept the regular operations applied to $A$ and $B$.

		% Commands to save me typing underscores everywhere
		% I want these scoped to the proof.
			\newcommand{\ma}{\ensuremath{M_A}\xspace}
				\newcommand{\qa}{\ensuremath{Q_A}\xspace}
				\newcommand{\siga}{\ensuremath{\Sigma_A}\xspace}
				\newcommand{\sa}{\ensuremath{s_A}\xspace}
				\newcommand{\dala}{\ensuremath{\delta_A}\xspace}
				\newcommand{\fa}{\ensuremath{F_A}\xspace}

			\newcommand{\mb}{\ensuremath{M_B}\xspace}
				\newcommand{\qb}{\ensuremath{Q_B}\xspace}
				\newcommand{\sigb}{\ensuremath{\Sigma_B}\xspace}
				\renewcommand{\sb}{\ensuremath{s_B}\xspace}
				\newcommand{\dalb}{\ensuremath{\delta_B}\xspace}
				\newcommand{\fb}{\ensuremath{F_B}\xspace}

			\newcommand{\mab}{\ensuremath{M_{AB}}\xspace}
				\newcommand{\qab}{\ensuremath{Q_{AB}}\xspace}
				\newcommand{\sigab}{\ensuremath{\Sigma_{AB}}\xspace}
				\newcommand{\sab}{\ensuremath{s_{AB}}\xspace}
				\newcommand{\dalab}{\ensuremath{\delta_{AB}}\xspace}
				\newcommand{\fab}{\ensuremath{F_{AB}}\xspace}

			\newcommand{\maub}{\ensuremath{M_{\cup}}\xspace}
				\newcommand{\qaub}{\ensuremath{Q_{\cup}}\xspace}
				\newcommand{\sigaub}{\ensuremath{\Sigma_{\cup}}\xspace}
				\newcommand{\saub}{\ensuremath{s_{\cup}}\xspace}
				\newcommand{\dalaub}{\ensuremath{\delta_{\cup}}\xspace}
				\newcommand{\faub}{\ensuremath{F_{\cup}}\xspace}

			\newcommand{\mas}{\ensuremath{M_{A^*}}\xspace}
				\newcommand{\qas}{\ensuremath{Q_{A^*}}\xspace}
				\newcommand{\sigas}{\ensuremath{\Sigma_{A^*}}\xspace}
				\newcommand{\sas}{\ensuremath{s_{A^*}}\xspace}
				\newcommand{\dalas}{\ensuremath{\delta_{A^*}}\xspace}
				\newcommand{\fas}{\ensuremath{F_{A^*}}\xspace}




		Let 
		\[
			M_A = (Q_A, \Sigma_A, s_A, \delta_A, F_A) \quad \text{ and } \quad M_B = (Q_B, \Sigma_B, s_B, \delta_B, F_B)
		\]
		be NDFAs such that $L(\ma) = A$ and $L(\mb) = B$.

		\begin{figure}[H]
			\centering
			\subfloat[\ma]{
				\label{sfig:ma}
				\begin{tikzpicture}[>=stealth',shorten >=1pt,auto,node distance=2cm]
					\node[initial,state]    (q0)                   {\sa};
					\node[elliptic state]   (ma)  [right of  = q0] {$\quad \ma \quad$};
					\node[state, accepting] (fa)  [right of = ma]  {\fa};
					\path[->](q0) edge (ma);
					\path[->](ma) edge (fa);
				\end{tikzpicture}
			}\\
			\subfloat[\mb]{
				\label{sfig:mb}
				\begin{tikzpicture}[>=stealth',shorten >=1pt,auto,node distance=2cm]
					\node[initial,state]    (q0)                   {\sb};
					\node[elliptic state]   (mb)  [right of  = q0] {$\quad \mb \quad$};
					\node[state, accepting] (fb)  [right of = ma]  {\fb};
					\path[->](q0) edge (mb);
					\path[->](mb) edge (fb);
				\end{tikzpicture}
			}
			\caption{
				NDFAs accepting $A$ and $B$.
				The leftmost vertices represent the set of accepting states, and the middle vertices represent all the states that are neither initial states nor accepting states.
				Note that if \ma or \mb accepts $\lambda$, its initial state must be an accepting state.
			}
			\label{fig:ma_and_mb}
		\end{figure}

		\noindent \textbf{(i)} \hspace{\parindent}
		We will construct an NDFA 
		\[
			M_{AB} = (Q_{AB}, \Sigma_{AB}, s_{AB}, \delta_{AB}, F_{AB})
		\]
		such that $L(\mab) = AB$.
		We build \mab by adding \mb onto the end of \ma, so that a word accepted by \mab is of the form $xy$ where $x$ is accepted by \ma and $y$ is accepted by \mb.

		Clearly, the alphabet of \mab must include all the symbols used by \ma and \mb, thus $\sigab = \siga \cup \sigb$.
		
		The states of \mab are all the states of both \ma and \mb.
		Since the names of states are meaningless, we can rename them at will. 
		This allows us to assume that \qa and \qb are disjoint, and write $\qab = \qa \cup \qb$.
		The initial state of \mab is the initial state of \ma, so $\sab = \sa$.

		The accepting states of \mab are the accepting states of \mb.
		If $\lambda$ is accepted by \mb, then \sb must be an accepting state of \mb, so that condition is accounted for.
		If $\lambda$ is accepted by both \ma and \mb, then $\lambda \in AB$, and \sab must be an accepting state.
		So we define
		\[
			\fab = 	\begin{cases}
						\fb \cup \{ \sab = \sa \} &\text{if } \lambda \in A \cap B \\
						\fb &\text{otherwise}
					\end{cases}
		\]
		We have not yet accounted for the case in which $\lambda \in A$ and $\lambda \notin B$.
		Doing so requires adding transitions to \mab.

		Now we must define \dalab.
		\mab should retain all the transitions of \ma and \mb, so for all $q_A \in \qa$ and $a \in \siga$, and for all $q_B \in \qb$ and $b \in \sigb$ we define
		\[
			\dala(q_A, a) \subseteq \dalab(q_A, a) \enspace \text{ and } \enspace \dalb(q_B, b) \subseteq \dalab(q_B, b).
		\]
		We also define new transitions so that any string accepted by \ma will take \mab from \sa to \sb.
		To do this, we add transitions to \sb that mimic the transitions to accepting states of \ma.
		For each transition whose result is an accepting state of \ma, we add a transition with the same origin on the same symbol leading to \sb.
		So for all $q_A \in \qa$ and $a \in \siga$ such that 
		\[
			\dala(q_A, a) \subseteq \fa
		\]
		we define
		\[
			\sb \in \dalab(q_A, a).
		\]
		These additions are represented in Figure~\ref{fig:mab_final} by the transition from \ma to \sb.

		Finally, we must account for the case in which $\lambda \in A$.
		In this case, \mab must be able to skip over \ma and accept strings of $B$ without any prefix.
		Hence if $\lambda \in A$ we must create transitions from \sa which shadow the transitions from \sb.
		Thus for all $b \in \sigb$ we define
		\[
			\dalb(\sb, b) \subseteq \dalab(\sa, b).
		\]
		These transitions are represented in Figure~\ref{fig:mab_final} by the dotted line from \sa to \mb.
		\begin{figure}[H]
			\centering
				\begin{tikzpicture}[>=stealth',shorten >=1pt,auto,node distance=3cm]
					\node[initial,state]    (sab)                   {\sa};
					\node[elliptic state]   (ma)  [right of = sab]  {$\quad \ma \quad$};
					\node[state]            (fa)  [right of = ma]   {\fa};

					\node[state]            (sb)  [below of = ma, node distance = 2cm]  {\sb};
					\node[elliptic state]   (mb)  [right of = sb]         {$\quad \mb \quad$};
					\node[state, accepting] (fb)  [right of = mb]         {\fb};

					\path[->](sab) edge (ma);
					\path[->](ma) edge (fa);

					\path[->](sb) edge (mb);
					\path[->](mb) edge (fb);

					\path[->](ma) edge  [out=0, in=180, below, distance=4cm]          (sb);
					\path[->](sab) edge [dashed,out=0, in=180, below, distance=2cm]   (mb);

					\node  (sab_label)   [below of = sab,node distance=1cm, text width=3cm] {\footnotesize{Accepting when\\$\lambda \in A \cap B$}};
					\node  (sab_label)   [below of = sb,node distance=1cm, text width=3cm]  {\footnotesize{Accepting when\\$\lambda \in  B$}};
				\end{tikzpicture}
			\caption{
				The completed automaton \mab.
				The dashed line is included only if $\lambda$ is accepted by \ma.
			}
			\label{fig:mab_final}
		\end{figure}
		This completes the construction of \mab.

		% AuB
		\noindent \textbf{(ii)} \hspace{\parindent}
		Now we construct an NDFA 
		\[
			% I'm well aware that this notation is weird, but I thnink it looks better than the alternative.
			\maub = (\qaub, \sigaub, \saub, \dalaub, \faub)
		\] 
		such that $L(\maub) = A \cup B$.
		We build \maub by combining \ma and \mb in parallel, so that a string will be accepted by \maub if it leads to an accepting state of either \ma or \mb.
		
		Clearly we need $\sigaub = \siga \cup \sigb$.

		The states of \maub are all the states of \ma and \mb, plus a new initial state \saub, which will have transitions into both \ma and \mb.
		So we define 
		\[
			\qaub = \qa \cup \qb \cup \{ \saub \}.
		\]

		We want \maub to accept strings of both $A$ and $B$, so all accepting states of \ma and \mb will be accepting states of \maub.
		If $\lambda$ is accepted by either \ma or \mb, we need \saub to be an accepting state. 
		Thus we define 
		\[
			\faub =	\begin{cases}
						\fa \cup \fb \cup \{ \saub \} &\text{if } \lambda \in A \cup B \\
						\fa \cup \fb &\text{otherwise}
					\end{cases}
		\]

		We keep all the transitions of \ma and \mb, setting $\dalaub \subseteq \dala \cup \dalb$, and add new transitions linking the new initial state to the rest of the automaton.
		For each transition from the initial state of \ma or \mb, we add a transition from \saub on the same symbol with the same destination.
		That is, for all $a \in \siga$ and all $b \in \sigb$, we define
		\[
			\dala(\sa, a) \subseteq \dalaub(\saub, a) \quad \text{and} \quad \dalb(\sb, b) \subseteq \dalaub(\saub, b).
		\]
		These are the transitions originating at \saub in Figure~\ref{fig:maub_final}.

		\begin{figure}[H]
			\centering
				\begin{tikzpicture}[>=stealth',shorten >=1pt,auto,node distance=3cm]
					\node[initial,state]    (sab)                             {\saub};

					\node[state]            (sa)  [above right of = sab]      {\sa};
					\node[elliptic state]   (ma)  [right of = sa]             {$\quad \ma \quad$};
					\node[state,accepting]  (fa)  [right of = ma]             {\fa};

					\node[state]            (sb)  [below right of = sab]      {\sb};
					\node[elliptic state]   (mb)  [right of = sb]             {$\quad \mb \quad$};
					\node[state, accepting] (fb)  [right of = mb]             {\fb};

					\path[->](sa) edge (ma);
					\path[->](ma) edge (fa);

					\path[->](sb) edge (mb);
					\path[->](mb) edge (fb);

					\path[->](sab) edge [out=0, in=180, distance = 2 cm] (ma);
					\path[->](sab) edge [out=0, in=180, distance = 2 cm] (mb);

					\node  (sab_label)   [below of = sab,node distance=1cm, text width=3cm] {\footnotesize{Accepting when\\$\lambda \in A \cup B$}};
				\end{tikzpicture}
			\caption{
				The automaton \maub.
				The transitions from \saub mimic those from \sa and \sb. 
			}
			\label{fig:maub_final}
		\end{figure}
		
		This completes the construction of \maub.

		% A*
		\noindent \textbf{(iii)} \hspace{\parindent}
		We construct \mas to accept $A^*$ by linking \ma to itself to form a circle. % Circularize!
		Since \mas should accept strings of $A$ repeated any number of times, we allow the accepting states of \ma to behave like initial states by adding transitions from \fa looping back into \ma.
		To allow \mas to accept $\lambda$, we create a new accepting state, \sas, to replace \sa as initial state.

		Let $\mas = (\qas, \siga, \sas, \dalas, \fas)$.
		Note that the alphabet of \mas is exactly the alphabet of \ma.

		We define $\qas = \qa \cup \{ \sas \}$ and $\fas = \fa \cup \{ \sas \}$, where \sas is the new initial state.

		We keep all the transitions of \ma, and for every transition from \sa, we add a transition to the same state on the same symbol from each state in \fas.
		That is, for all $a \in \siga$ and $f \in \fas$ we define 
		\[
			\dala(\sa, a) \subseteq \dalas(f, a) 
		\]
		Note that since \sas is an accepting state, this also gives \sas a copy of each of the transitions from \sa.

		\begin{figure}[H]
			\centering
				\begin{tikzpicture}[>=stealth',shorten >=1pt,auto,node distance=2.5cm]
					\node[initial,accepting,state]    (sas)                   {\sas};
					\node[state]            (sa)  [right of = sas]            {\sa};
					\node[elliptic state]   (ma)  [right of = sa]             {$\quad \ma \quad$};
					\node[state,accepting]  (fa)  [right of = ma]             {\fa};

					\path[->](sa) edge (ma);
					\path[->](ma) edge (fa);

					\node (ghost_start)  [above of = sa,         node distance = 1 cm,   inner sep = 0 cm] {};
					\node (ghost_start2) [left of  =ghost_start, node distance = 0.1 cm, inner sep = 0 cm] {};

					\path[-] (sas)          edge [out=0, in=180, above, distance = 1 cm] (ghost_start);
					\path[-] (ghost_start)  edge [out=0, in=180]                         (ghost_start2);
					\path[->](ghost_start)  edge [out=0, in=180, above, distance = 1 cm] (ma);

					% I tried a Bezier, but I'd need more than 4 control points to get the results I want
					\node (ghost_end)  [below of = fa,        node distance = 1.2 cm, inner sep = 0 cm] {};
					\node (ghost_end2) [right of = ghost_end, node distance = 0.2 pt, inner sep = 0 cm] {};
					\node (ghost_mid)  [below of = ma,        node distance = 1.2 cm, inner sep = 0 cm] {};
					\node (ghost_mid2) [left of  = ghost_mid, node distance = 0.2 cm, inner sep = 0 cm] {};

					\path[-]  (fa)         edge [out=0,   in=0,   below, distance = 1.5 cm] (ghost_end);
					\path[-]  (ghost_end2) edge [out=180, in=0]                             (ghost_end);
					\path[-]  (ghost_end)  edge [out=180, in=0]                             (ghost_mid);
					\path[-]  (ghost_mid2) edge [out=0,   in=0]                             (ghost_mid);
					\path[<-] (ma)         edge [out=180, in=180, below, distance = 1.5 cm] (ghost_mid);

				\end{tikzpicture}
			\caption{
				The completed form of \mas.
				The new initial state allows \mas to accept $\lambda$, while the transitions from the final states of \ma allow it to accept repeated words from $A$.
			}
			\label{fig:mas_final}
		\end{figure}

		This completes the construction of \mas.
		We can now construct an NDFA to accept any regular language.
	\end{proof}

	\begin{claim}
	\label{prop:ndfa_dfa_equivalent}
		A language is representable by an NDFA if and only if it is representable by a DFA.
	\end{claim}
	\begin{proof}
	\label{proof:ndfa_dfa_equivalent}
		(Adapted from Hopcroft and Ullman \footcite{hopcroft}{22}.)
		Since every DFA is an NDFA, every language represented by a DFA is trivially represented by an NDFA.
		We need only prove that any language represented by an NDFA can be represented by a DFA.

		Let $M = (Q, \Sigma, s, \delta, F)$ be an NDFA.
		We will construct a DFA $M'$ such that $L(M') = L(M)$.

		Because $M$ is nondeterministic, any subset of its states may be active at any given time.
		$M'$ must have one state representing each possible set of active states of $M$, so $Q'$ must be the power set of $Q$.
		Thus each state in $Q'$ will be denoted by a set of the form $\{ q_1, q_2, \dots, q_n \}$ where all $q_i \in Q$.
		The initial state of $M'$ is the set $\{ s \}$, which contains only the initial state of $M$.
		The accepting states of $M'$ are the subsets of $Q$ that contain an accepting state of $M'$.

		We have defined
		\[
			M' = (Q', \Sigma, \{s\}, \delta', F')
		\]
		where
		\[
			F' = \{ p \in Q' \mid p \cap F \neq \emptyset\}.
		\]

		The only component of $M'$ remaining to be defined is the transition function.
		We define the result of each transition of $\delta'$ as a union of transitions of $\delta$.
		For each $\{ q_1, q_2, \dots, q_n \} \in Q'$ and all $a \in \Sigma$, we define
		\begin{align*}
			\delta'(\{ q_1, q_2, \dots, q_n \}, a) &= \delta(q_1, a) \cup \delta(q_2, a) \cup \dots \cup \delta(q_n, a) \} \\
			&= \bigcup_{i=1}^n \delta(q_i, a)
		\end{align*}
		
		This completes the construction of $M'$.

		Now we must prove that $L(M') = L(M)$, which is equivalent to proving that the active state of $M'$ always represents exactly the set of active states of $M$, given the same input.
		That is:
		\[
			\Delta'(\{ s \}, w) = \Delta(s, w) \text{ for any string } w \in \Sigma^*.
		\]
		
		We will proceed by induction on the length of the sting $w$.
		Suppose that $|w| = 0$.
		Then $w = \lambda$, and $M$ will remain in its initial state, so 
		\[
			\delta'(\{ s \}, \lambda) = \{ s \} = \delta(s, \lambda).
		\]

		Now suppose that $\Delta'(\{ s \}, w) = \Delta(s, w)$ for all $w \in \Sigma^*$ with $|w| \leq N$.
		Let $w \in \Sigma^*$ be of length $N$, and let $a \in \Sigma$. 
		Then $|wa| = N + 1$.
		
		We know by definition that 
		\[
			\Delta'(\{ s\}, wa) = \delta'( \Delta'(\{ s\}, w), a )
		\]
		and since $|w| \leq N$, we can write 
		\[
			\Delta'(\{ s \}, w) = \{ p_1, p_2, \dots, p_m \} = \Delta(s, w).
		\]
		Thus
		\begin{align*}
			\delta'( \Delta'(\{ s \}, w), a ) &= \delta'(\{ p_1, p_2, \dots, p_m \}, a) \\
			&= \bigcup_{i=1}^m \delta(p_i, a)
		\end{align*}

		Thus we know that $\Delta'(\{ s \}, w) = \Delta(s, w)$ for $w$ of length $N+1$.

	\end{proof}

	\begin{claim}
	\label{prop:representable_languages_regular}
		All representable languages are regular.
	\end{claim}

	\begin{proof}
		(Adapted from Salomaa \footcite{salomaa}{29}.)
		Because we have proven that every language accepted by an NDFA is accepted by a DFA, it is enough to show that any language represented by a DFA is regular.

		Let $M = (Q, \Sigma, s, \delta, F)$ be a DFA, and let $Q = \{ q_1, \dots, q_n \}$ with $n \geq 1$.

		Define $W_k(i, j)$ to be the language containing all words that take $M$ from $q_i$ to $q_j$ without transiting any state $q_l$ with $l > k$.

		Then for $k = 0$:
		\[
			W_0(i, j) = \{ a \in \Sigma \cup \{ \lambda \} \mid \delta(q_i, a) = q_j \}.
		\]
		That is, $W_0(i, j)$ is the set of strings that take $M$ from $q_i$ to $q_j$ without passing through any intermediate states.
		Clearly, every element of this set must be either a symbol of $\Sigma$ or, if and only if $i = j$, the empty string.
		So for all $i$ and $j$, $W_0(i, j)$ must be of one of the following forms:
		\begin{enumerate}[label=(\roman*), itemsep = -0.3 ex, nolistsep]
			\item $\emptyset$
			\item $\{ \lambda \}$
			\item $\{ \lambda, a_1, a_2, \dots, a_m \}, \ a_i \in \Sigma$
			\item $\{ a_1, a_2, \dots, a_m \}$
		\end{enumerate}
		Clearly, each of these is a regular language:
		$\emptyset$ and $\{ \lambda \}$ are atomic regular languages, and it is trivial to rewrite $\{ \lambda, a_1, a_2, \dots, a_m \}$ or $\{ a_1, a_2, \dots, a_m \}$ as the union of atomic regular languages.
		Thus $W(i, j, 0)$ is regular for all $1 \leq i, j \leq n$.

		For $k \geq 1$ we define
		\[
			W_k(i, j) = W_{k-1}(i, j) \cup W_{k-1}(i, k) \ W_{k-1}(k, k)^* \ W_{k-1}(k, j).
		\]
		That is, $W_k(i, j)$ is the union of two languages:
		The first is the language of all strings that take $M$ from $q_i$ to $q_j$ using vertices numbered less than $k$.
		The second is the language containing all stings of the form $xyz$, where $x$ takes $M$ from $q_i$ to $q_k$, $y$ takes $M$ from $q_k$ to $q_k$ and $z$ takes $M$ from $q_k$ to $q_j$, all using only states numbered less than $k$.

		Now assume that any $W_k(i, j)$ is regular for all $k \leq l$.
		We will show that all $W_{l+1}(i, j)$ are regular.

		For all $i$ and $j$, we know that 
		\[
			W_{l+1}(i, j) = W_l(i, j) \ \cup \ W_l(i, k)\ W_l(l+1, l+1)^* \ W_l(l+1, j).
		\]
		By our inductive hypothesis, we know that the languages 
		\begin{enumerate}[label = (\roman*), itemsep = -0.3 ex, nolistsep]
			\item $W_l(i, j)$
			\item $W_l(i, k)$
			\item $W_l(l+1, l+1)$
			\item $W_l(l+1, j)$
		\end{enumerate}
		are all regular.
		Thus $W_l(l+1, l+1)^*$ is regular as the Kleene closure of a regular language, and 
		\[
			W_l(i, k)\, W_l(l+1, l+1)^*\, W_l(l+1, j)
		\] 
		is regular as a concatenation of regular languages.
		Thus $W_{l+1}(i, j)$ is regular as a union of regular languages.

		Suppose that $q_1$ is the initial state of $M$.
		Then the language accepted by $M$ is given by
		\[
			\bigcup_{q_j \in F} W_n(1, j).
		\]
		This must be regular as a union of regular languages.
	\end{proof}
	

	This completes the proof of Kleene's theorem.

% chapter kleenes_theorem (end)


\mychapter{Examples Illustrating Kleene's Theorem} % (fold)
\label{sec:examples}

	\section{Mod 3 Finite Automaton} % (fold)
	\label{sec:mod_3_finite_automaton}
	
		To understand the proof of \refprop{prop:representable_languages_regular} it is helpful to see the induction applied to an actual automaton.
		For this example it is easier to deal in regular expressions than in set notation, so we define $R_k(i, j)$ to be the regular expression representing the language $W_k (i, j)$:
		\begin{align*}
			R_0(i, j) &= a_1 + a_2 + \cdots \text{ for all } \{ a_m \in \Sigma \cup \{ \lambda \} \mid \delta(q_i, a_m) = q_j \} \\
			\text{and}\\
			R_{k+1}(i, j) &= R_k(i, j) + \big( R_k(i, k) \ (R_k(k+1, k+1))^* \ R_k(k, j) \big)
		\end{align*}
		

		Consider the FA $M_3$, as defined in section~\ref{sec:ex:m3_construction}.
		To follow along with the proof of \refprop{prop:representable_languages_regular}, we must define a numbering of the states of $M_3$ that begins at one, rather than 0.
		For now, we use the numbering
		\begin{align*}
			q_0 &\to 3, \\
			q_1 &\to 1, \\
			q_2 &\to 2.
		\end{align*}
		This gives us the automaton shown in Figure~\ref{fig:m3_numbered_312}
		
		\begin{figure}[H]
			\centering
			\begin{tikzpicture}[>=stealth',shorten >= 1 pt, auto, node distance = 2 cm]
				\node[initial,state,accepting] (q0)                 {$q_3$};
				\node[state]                   (q1) [right of = q0] {$q_1$};
				\node[state]                   (q2) [right of = q1] {$q_2$};

				\path[->](q0) edge [loop above] node {0} (q0);
				\path[->](q0) edge [bend left]  node {1} (q1);
				\path[->](q1) edge [bend left]  node {0} (q2);
				\path[->](q1) edge [bend left]  node {1} (q0);
				\path[->](q2) edge [bend left]  node {0} (q1);
				\path[->](q2) edge [loop right] node {1} (q2);
			\end{tikzpicture}
			\caption{
				The DFA $M_3$ with a new numbering.
			}
			\label{fig:m3_numbered_312}
		\end{figure}

		With this numbering in place, we begin by examining $R_0(i, j)$ for all $i, j$.
		If we place the values in a $3 \times 3$ matrix, we obtain:
		\[
			R_0 (i, j) = 
			\begin{bmatrix*}[l]
				\lambda 	& 0				& 1 			\\
				0 			& \lambda + 1 	& \emptyset		\\
				1 			& \emptyset 	& \lambda + 0 	\\
			\end{bmatrix*}
		\]

		This matrix simply shows the symbols attached to direct transitions from one state to another.
		Now we combine the entries in this matrix to construct the matrix for $R_1(i, j)$.
		Note the changes in bold. 
		The combined expressions quickly grow in size, so these have been simplified wherever possible:
		\[
			R_1 (i, j) = 
			\begin{bmatrix*}[l]
				\lambda 	& 0							& 1 						\\
				0 			& \lambda+1+\bm{00} 	& \bm{01}				\\
				1 			& \bm{10} 				& \lambda+0+\bm{11} 	\\
			\end{bmatrix*}
		\]

		The entries in this matrix are the strings that take $M_3$ from state $i$ to state $j$, either directly or by passing through only state $q_1$ in between.
		For example, it is possible to get from $q_3$ to $q_2$ and vice-versa via $q_1$.
		Combining these entires, we obtain the following matrix for $R_2(i, j)$:
		\[
			R_2 (i, j) = 
			\begin{bmatrix*}[l]
				\lambda + \bm{0(1+00)^*0} 	& 0+\bm{0(1+00)^*}		& 1+\bm{0(1+00)^*01}		\\
				0+\bm{(1+00)^*0} 			& \bm{(}1+00\bm{)^{*}} 	& \bm{(1+00)^*}01			\\
				1+\bm{(10(1+00)^*0)} 		& 10\bm{(1+00)^*} 		& (\lambda+0+11)+\bm{10(1+00)^*01} 	\\
			\end{bmatrix*}
		\]
		% Beyond this, the matrix would be too large to fit in the width of a page.
		This matrix gives all the strings attached to paths from $q_i$ to $q_j$ that do not pass through $q_3$.
		Let us dissect one entry in this matrix, the expression $R_2(3, 1)$:
		\[
			1+(10(1+00)^*0).
		\]
		We can see that the expression describes the union of two languages.
		The first language is quite simple: the string ``1'' labels a direct transition from $q_3$ to $q_1$.
		Since we are not considering paths that transit $q_3$, we can surmise that the second part of the expression describes paths from $q_3$ to $q_1$ via $q_2$.

		Now let us consider the second language, described by $10 (1+00)^* 0$.
		Clearly, all strings in this language begin ``10'', which labels a path from $q_3$ to $q_2$ via $q_1$.
		Next, we have either $\lambda$, or a string made up of ``1'' and ``00'' repeated any number of times.
		We can see that ``1'' will lead from $q_2$ back to itself, and that ``00'' will lead to $q_1$ and back to $q_2$.
		Finally, all strings in this language must end in ``0'', which will lead from $q_2$ to $q_1$.
		So the regular expression $10 (1+00)^* 0$ describes all strings that lead from $q_3$ to $q_2$, then back to $q_2$, and finally lead to $q_1$.

		Now let us consider a different numbering on the same automaton:
		\begin{align*}
			q_0 &\to 2, \\
			q_1 &\to 3, \\
			q_2 &\to 1.
		\end{align*}
		This is a fairly counter-intuitive numbering --- unlike our previous numbering, it gives each state a number that has nothing to do with the value of the current input modulus 3.
		\meo{The careful reader might already be able to tell why this numbering will produce interesting results.}
		This yields the automaton shown in Figure~\ref{fig:m3_numbered_231}

		\begin{figure}[H]
			\centering
			\begin{tikzpicture}[>=stealth',shorten >= 1 pt, auto, node distance = 2 cm]
				\node[initial,state,accepting] (q0)                 {$q_2$};
				\node[state]                   (q1) [right of = q0] {$q_3$};
				\node[state]                   (q2) [right of = q1] {$q_1$};

				\path[->](q0) edge [loop above] node {0} (q0);
				\path[->](q0) edge [bend left]  node {1} (q1);
				\path[->](q1) edge [bend left]  node {0} (q2);
				\path[->](q1) edge [bend left]  node {1} (q0);
				\path[->](q2) edge [bend left]  node {0} (q1);
				\path[->](q2) edge [loop right] node {1} (q2);
			\end{tikzpicture}
			\caption{
				The DFA $M_3$ with the counter-intuitive numbering.
			}
			\label{fig:m3_numbered_231}
		\end{figure}

		We will denote the regular expressions associated with this numbering by $R'_k(i, j)$.
		Wherever there is ambiguity, we will mark symbols in the same way.
		\[
			R'_0 (i, j) = 
			\begin{bmatrix*}[l]
				\lambda + 1	& \emptyset		& 0 			\\
				\emptyset 	& \lambda + 0 	& 1				\\
				0 			& 1 			& \lambda 		\\
			\end{bmatrix*}
		\]

		

		\[
			R'_1 (i, j) = 
			\begin{bmatrix*}[l]
				\bm{1^*}	& \emptyset		& \bm{1^*}0 					\\
				\emptyset 	& \lambda + 0 	& 1								\\
				0\bm{1^*} 	& 1 			& \lambda+\bm{(0 1^* 0)} 		\\
			\end{bmatrix*}
		\]

		\[
			R'_2 (i, j) = 
			\begin{bmatrix*}[l]
				1^*			& \emptyset		& 1^*0 										\\
				\emptyset 	& \bm{0*}		& \bm{0^*}1									\\
				01^* 		& 1\bm{0^*} 	& \lambda + 01^*0 + \bm{1 0^* 1} 			\\
			\end{bmatrix*}
		\]
		Since the state in the center of the machine, which links the other two states, is now numbered $3$, we see that there are still no paths available from $q'_2$ to $q'_1$ or vice-versa in the matrix of $R'_2(i, j)$.
		Contrast with $R_1 (i, j)$, in which it is possible to find a path from any state to any other, despite the transitions used being restricted transiting a smaller set of states.

		We previously examined
		\[
			R_2(3, 1) = 1 + (10 (1 + 00)^* 0).
		\]
		Since states $1$ and $3$ in the previous numbering are equivalent to states $2'$ and $3'$, respectively, in our current numbering, let us examine
		\[
			R'_2(2', 3') = 0^*1.
		\]
		This is clearly a very different expression.
		By Figure~\ref{fig:m3_numbered_231} we see that $0^*$ leads from $q'_2$ back to itself, and ``1'' labels a direct transition from $q'_2$ to $q'_3$.

		Recall that the language represented by a DFA having $n$ states is given by 
		\[
			\bigcup_{q_j \in F} W_n(s, q_j).
		\]
		The only accepting state of $M_3$ is also its initial state, so let us compare the regular expressions for the language accepted by $M_3$ as generated by our two numberings:
		\begin{align*}
			R_3(3, 3) &= (0+11+(10 \, (1+00)^* \, 01))^* \\
			\text{and} \\
			R'_3(2, 2) &= 0^* + (0^*1 \, ((01^*0) + (10^*1))^* \, 10^*).
		\end{align*}

		These two expressions must represent the same language, despite appearing very different.
		To confirm that this is the case let us examine each in detail.

		Observe that the first expression describes the Kleene closure of a union of three languages.
		The first two of these are ``0'' and ``11''.
		Consulting Figure~\ref{fig:m3_numbered_312}, it should be apparent how these denote paths from $q_3$ back to $q_3$.
		The third language is described by $10 (1+00)^* 01$.
		This gives all the strings that lead from $q_3$ to $q_2$, return to $q_2$ any number of times, then lead back to $q_3$.

		The union of these three languages gives us the language of strings that lead $M_3$ from $q_3$ back to $q_3$, whether directly or by transiting the other states of the machine. 
		Thus the Kleene closure of this union gives us the language of all such strings repeated any number of times.

		Now we turn our attention to $R'_3(2, 2)$.
		We can see that it denotes the union of two languages: one described by $0^*$ and one described by 
		\begin{equation}
		\label{eq:r3_22}
			0^*1 ((01^*0) + (10^*1))^* 10^*
		\end{equation}
		The first language is clearly the set of strings $\{ \lambda, 0, 00, 000, \dots \}$, which takes $q'_2$ to $q'_2$ without any intermediate vertices.
		Then if the entire expression gives the language accepted by $M_3$, then \ref{eq:r3_22} must describe the strings that take $q'_2$ to $q'_2$ passing through any intermediate states.
		To confirm this hypothesis, let us examine this expression piece-by-piece.

		The expression \ref{eq:r3_22} begins with $0^*1$ --- it is easy to see that this describes all the strings that lead from $q'_2$ to $q'_3$.
		Next, we have $((01^*0) + (10^*1))$. 
		Consulting Figure~\ref{fig:m3_numbered_231}, we can see that $01^*0$ describes all the strings that depart $q'_3$ and return via $q'_2$.
		Similarly, $10^*1$ describes all the strings that return to $q'_3$ via $q'_2$.
		Finally the \ref{eq:r3_22} ends $10^*$, which, as the mirror image of $0^*1$, denotes all the strings that lead from $q'_3$ to $q'_2$ and never enter another state.
		Concatenating all of these languages yields the set of strings that leave $q'_2$ and return through $q'_3$ and $q'_1$.
		Thus, as the union of this expression and $0^*$, \ref{eq:r3_22} denotes all the paths through $M_3$ that begin and end at $q'_2$.

		So we can see that our two expressions $R_3(3,3)$ and $R'_3(2, 2)$, however different they may appear, describe the same language.


	\meo{
		Figure out if there are any other parts of the proof that deserve an example to help explain them.
		I will probably include pictures for regular language $\iff$ representable in the initial proof.
		It would be nice to include a power set construction, but it would also end up being pretty long.
	}
	% section mod_3_finite_automaton (end)


% chapter examples (end)

\mychapter{Motivation} % (fold)
\label{sec:motivation}

	The relationship between regular languages and DFAs established by Kleene's theorem plays a significant role in the ubiquity of regular expression-based software tools. 
	In this chapter, we will discuss some of the formalisms used to leverage Kleene's theorem in practice and provide examples to demonstrate the power and utility of regular expressions.

	\section{Formalisms} % (fold)
	\label{sec:formalisms}
		This will be a brief overview of the formal underpinnings of regular expression (regexp) based tools.

		The most common type of regexp-based utility allows the user to enter a regular expression and search through some body of text for strings from the language described by the regular expression.
		The naive approach to this use-case is to convert the regular expression into a DFA, then input the text to the DFA and output the strings accepted by the DFA.
		
		This approach relies on the ability to convert a regular expression into a DFA, and then use that DFA to efficiently control the search.
		The proof of \refprop{prop:regular_languages_representable} on page \pageref{prop:regular_languages_representable} takes a first step towards an algorithm to convert a regular expression into an NDFA, and \refprop{prop:ndfa_dfa_equivalent} on page \pageref{prop:ndfa_dfa_equivalent} shows that the resulting NDFA could be converted into a DFA.
		The resulting machine, however, would likely have more states than desirable.
		Thus, this approach also relies on the existence of a minimal DFA (one having a minimal number of states) to represent any regular language, as well as the existence of an algorithm to minimize a DFA.
		We will not prove these results, but formal statements and proofs may be found in Hopcroft and Ullman \footcite{hopcroft}{65--71}.

		Assuming that we have a minimal DFA based on some regular expression, we must be able to use it to control the search through a body of text.
		That means minimizing the number of operations necessary to find the next state of the machine each time an input symbol is read.
		To this end, we now introduce the matrix representation of a DFA.

		\begin{definition}[Matrix of a DFA]
			Let $M = (Q, \Sigma, s, \delta, F)$ be a DFA with $n$ states $q_1, q_2, \dots, q_n$ and an alphabet of $m$ symbols $\sigma_1, \sigma_2, \dots, \sigma_n$.
			We may represent $M$ by the $n \times m$ matrix $\mathbf{M}$ given by 
			\[
				\mathbf{M}_{ij} = \delta(q_i, \sigma_j).
			\]
		\end{definition}

		Consider the $M_3$ DFA and its matrix, as depicted in Figure~\ref{fig:m3_and_matrix}.

		\begin{figure}[H]
			\setlength{\fboxrule}{0 pt}
			\centering
			\subfloat[$M_3$ as previously constructed.]{
			\label{sfig:m3_for_matrix}
				\begin{tikzpicture}[>=stealth',shorten >=1pt,auto,node distance=1.6cm]
					\node[initial,state,accepting] (q0)                {$q_0$};
					\node[state]                   (q1) [right of = q0] {$q_1$};
					\node[state]                   (q2) [right of = q1] {$q_2$};

					\path[->](q0) edge [loop above] node {0} (q0);
					\path[->](q0) edge [bend left]  node {1} (q1);
					\path[->](q1) edge [bend left]  node {0} (q2);
					\path[->](q1) edge [bend left]  node {1} (q0);
					\path[->](q2) edge [bend left]  node {0} (q1);
					\path[->](q2) edge [loop right] node {1} (q2);
				\end{tikzpicture}
			} \\
			\subfloat[The matrix representing $M_3$]{
			\label{sfig:m3_matrix}
				\framebox[0.5 \textwidth]{
				\begin{tabular}{c c c}
									& $\mathbf{0}$ 	& $\mathbf{1}$ \\
					$\mathbf{q_0}$	& $q_0$			& $q_1$ \\
					$\mathbf{q_1}$	& $q_2$			& $q_0$ \\
					$\mathbf{q_2}$	& $q_1$			& $q_2$ \\
				\end{tabular}
				}
			}
			\caption{
				$M_3$ and its matrix representation.
			}
			\label{fig:m3_and_matrix}
		\end{figure}

		The matrix representation of a DFA allows the result of all transitions to be precomputed and stored, so that finding the next state for each input symbol is as simple as accessing the correct entry in an array.
		This operation takes constant ($\bigo(1)$) time.
		If there are $N$ symbols in some body of text, then our program will demand $N$ of these $\bigo(1)$ operations, which means that it will take $\bigo(N)$ time.
		This means that our program can produce all its output while reading through the body of text only once.
		This pre-computation may itself impose a significant performance penalty, but in practice this can be avoided \footcite{grep}{2--3}.
	% section formalisms (end)

	\section{Examples} % (fold)
	\label{sec:applications_examples}
		Probably the best known example of a regular expression based tool is the \texttt{grep} (Global Regular Expression Print) utility available near-universally on Unix-based computers \footcite{grep}{1}.
		This utility is almost exactly the program described above, it allows the user to specify a regular expression and some body of text, and outputs all the lines of the text containing a string matching the regular expression provided.
		Similar functionality is included in the standard libraries of most programming languages.
		Many word processors and text editors, even those designed for non-technical users, include a regular expression search functionality.

		Regular expressions are also used in the compilers and interpreters of programming languages.
		Many syntactical rules, such as what constitutes a valid variable name, are typically simple enough that a regular expression can be used to check that a variable name is valid \footcite{hopcroft}{45 -- 46}.

		The regular expressions used by tools in practice are considerably more complex than those we have defined.
		Table~\ref{tab:grep_regexps} gives some examples of the syntax used by \texttt{grep}:

		\begin{figure}[H]
			\begin{tabular}{r l}
				\textbf{Expression} 	& \textbf{Meaning} \\
				\hline
				$.$ 					& Any character \\
				$a$ 					& The letter $a$ \\
				$a?$ 					& $a$ once or zero times \\
				$a*$ 					& $a$ zero or more times \\
				$a+$ 					& $a$ one or more times \\
				$a \{ n, m \}$ 			& $a$ between $n$ and $m$ times \\
				$[\char`^{} abc]$ 		& any character except $a$, $b$, or $c$ \\
				$(a | b)$ 				& either $a$ or $b$ \\
			\end{tabular}
			\caption{
				A sampling of the regular expression syntax used by \texttt{grep} \cite{man_grep}.
				These examples are fairly standard across regexp-based utilities.
			}
			\label{tab:grep_regexps}
		\end{figure}

		Note that all of the expressions shown in Table~\ref{tab:grep_regexps} could be expressed our simple regular expression syntax, although in most cases the result would be a painfully large expression.
		In addition to these expressions, \texttt{grep} provides some extensions to regular expressions that actually allow for the description of non-regular languages, but these features are less standardized and less frequently used than the core regexp facilities.
	% section examples (end)
% chapter motivation (end)



\iffalse
\mychapter{Mathematical Notation}%
\label{ch:mathematical-notation}

You may find it useful to the reader to provide a table of notation. 

\mychapter{Conclusion(s)}
\label{ch:conclusion}
\fi

% chapter conclusion (end)


%\appendix
%%% Any appendices are delineated with the \appendix command.
%%% Individual appendices are begun with the standard \chapter or
%%% \section commands.  Use an appendix for any very long argument or side issue.

\backmatter

\nocite{*}
\bibliographystyle{plainnat}
\bibliography{references.bib}

\end{document}


